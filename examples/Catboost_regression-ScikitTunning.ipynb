{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "asian-envelope",
   "metadata": {},
   "source": [
    "# Catboost regression optmized by Model Goodness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-ethiopia",
   "metadata": {},
   "source": [
    "## Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c57432-0dee-4cac-b2c6-d3191d4d9a60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'UTuning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-75cc228bc33c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mr'C:\\Users\\eduar\\OneDrive\\PhD\\UTuning'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mUTuning\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'UTuning'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,r'C:\\Users\\eduar\\OneDrive\\PhD\\UTuning')\n",
    "\n",
    "from UTuning import scorer, plots\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b91f1-19e6-4a08-8723-9208fd8a3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\eduar\\OneDrive\\PhD\\UTuning\\dataset\\unconv_MV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e46c78-0522-4dee-8568-a6bd74b38f72",
   "metadata": {},
   "source": [
    "## Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313055c2-e0d9-43b2-a8e0-e42de8cefb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Production'].values\n",
    "X=df[['Por','LogPerm','Brittle','TOC']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7576c-6412-42d1-b59e-9b281402796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2ea47-2450-4eee-9609-830e7b16277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d7184-5e1b-46c1-95c9-0bccfa47661a",
   "metadata": {},
   "source": [
    "## Model definition and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac974d9e-7bbe-4eb6-a2d9-50aa07d03735",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=500, learning_rate=0.2, loss_function='RMSEWithUncertainty',\n",
    "                          verbose=False, random_seed=0)\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b3cda-d83c-4fa8-9f0a-2b35df70c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560fc5a-181e-4355-a86b-f5db5423201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff9ace-228f-4ecf-bc9d-4c1c87c86fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.error_line(estimates[:,0],y_test,estimates[:,1],Frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab35f8-c9b4-4472-bc5b-e9d5b5bf6836",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941be4b5-f622-42c4-a6a2-2307bf60d804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05474039-44f7-45ef-9ad5-b016103f7d11",
   "metadata": {},
   "source": [
    "## Scikit-learn hyperparameter optmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22421f65-5864-4b44-9a7c-cb49b83a92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "#from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec534c2-fb31-4c77-81a4-96a189d41560",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = list(np.arange(10, 200, step=10))\n",
    "lr = list(np.arange(0.01, 0.1, step=.01))\n",
    "param_grid = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"n_estimators\": max_depth\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de233e67-9d20-46a9-ad21-5beaed5d509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def APG_calc(Truth, Pred, Sigma,n_quantiles):\n",
    "    mask = np.random.choice([False, True],\n",
    "                            len(Pred),\n",
    "                            p=[0, 1]) # To display randomly less points [Remove , Keep] in fraction\n",
    "\n",
    "    Pred=Pred[mask]\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "\n",
    "    F = np.zeros(Pred.shape[0])\n",
    "    Indicator_func = np.zeros((Pred.shape[0], perc.shape[0]))\n",
    "\n",
    "    # range of symmetric p-probability intervals\n",
    "    plow = (1 - perc) / 2\n",
    "    pupp = (1 + perc) / 2\n",
    "    \n",
    "    for i in range(len(Pred)):\n",
    "        F[i] = stats.norm.cdf(Truth,\n",
    "                          loc=Pred[i],\n",
    "                          scale=Sigma)\n",
    "        for proba_low, proba_upp in zip(plow, pupp):\n",
    "            for k in range(len(plow)):\n",
    "                if plow[k] < F[i] <= pupp[k]:\n",
    "                    Indicator_func[i, k] = 1\n",
    "                else:\n",
    "                    Indicator_func[i, k] = 0\n",
    "\n",
    "    avgIndFunc = np.mean(Indicator_func, axis=0)\n",
    "\n",
    "    a = np.zeros(len(avgIndFunc))\n",
    "    for i in range(len(avgIndFunc)):\n",
    "        if avgIndFunc[i] > perc[i] or avgIndFunc[i] == perc[i]:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "    #print('Overall uncertainty = {0:2.2f}'.format(Sigma.mean()))\n",
    "    U = Sigma.mean()\n",
    "\n",
    "    Accuracy = integrate.simps(a, perc)\n",
    "\n",
    "    Prec = a*(avgIndFunc-perc)\n",
    "    \n",
    "    Precision = 1-2*integrate.simps(Prec, perc)\n",
    "\n",
    "    Sum = (3*a-2)*(avgIndFunc-perc)\n",
    "\n",
    "    Goodness = 1-integrate.simps(Sum, perc)\n",
    "    \n",
    "    return Accuracy, Precision, Goodness, avgIndFunc, U\n",
    "\n",
    "\n",
    "# def my_custom_loss_func(y_true, y_pred):\n",
    "    \n",
    "    \n",
    "\n",
    "#     L = 10\n",
    "#     mean = np.empty((L, len(perc)))\n",
    "\n",
    "#     for p_interv in range(len(perc)):\n",
    "#         for l in np.arange(0, L):\n",
    "#             samples = random.choices(IF_array[:, p_interv],\n",
    "#                                      k=IF_array.shape[0])\n",
    "#             mean[l, p_interv] = np.mean(samples)\n",
    "    \n",
    "#     return np.mean(Pred-Truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2e46d-dfbf-432c-ada2-ddfeccb8e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    \n",
    "    #diff = np.abs(y_true - y_pred[:,0])\n",
    "    \n",
    "    n_quantiles=11\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "    Samples = 10\n",
    "    \n",
    "    preds = y_pred\n",
    "\n",
    "    Pred = preds[:,0]\n",
    "    Sigma=np.sqrt(preds[:,1])\n",
    "    Truth = y_true\n",
    "    \n",
    "    Pred_array = np.zeros((Sigma.shape[0],Samples))\n",
    "\n",
    "    A_array=np.zeros(Pred.shape[0])\n",
    "    P_array=np.zeros(Pred.shape[0])\n",
    "    G_array=np.zeros(Pred.shape[0])\n",
    "    U_array=np.zeros(Pred.shape[0])\n",
    "\n",
    "    IF_array=np.zeros((Pred.shape[0],n_quantiles))\n",
    "\n",
    "    for i in range(len(Pred)):\n",
    "        Pred_array[i,:] = np.random.normal(loc=Pred[i],scale=Sigma[i],size=Samples)\n",
    "        A,P,G,IF,U=APG_calc(Truth[i], Pred_array[i,:], Sigma[i],n_quantiles)\n",
    "        U_array[i]=U\n",
    "        A_array[i]=A\n",
    "        P_array[i]=P\n",
    "        G_array[i]=G\n",
    "        IF_array[i,:] = IF\n",
    "\n",
    "    avgIndFunc = np.mean(IF_array, axis=0)\n",
    "\n",
    "    print('Accuracy = {0:1.2f}'.format(np.mean(A_array)))\n",
    "    print('Precision = {0:1.2f}'.format(np.mean(P_array)))\n",
    "    print('Goodness = {0:1.2f}'.format(np.mean(G_array)))\n",
    "\n",
    "    \n",
    "    return np.mean(G_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3a1a2-3153-4f0d-9f23-433263db0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = make_scorer(my_custom_loss_func,greater_is_better=True)\n",
    "# model=CatBoostRegressor(loss_function='RMSEWithUncertainty',\n",
    "#                         verbose = False)\n",
    "# clf=model.fit(X_train, y_train)\n",
    "\n",
    "# #preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab892cc-a905-4ce7-a62c-c4be09542e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af85177-b053-4e06-a104-3244321ea8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score(clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cc259-4144-4efd-8c72-5a2156cec9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostRegressor(iterations=100,\n",
    "#                           learning_rate=0.2,\n",
    "#                           loss_function='RMSEWithUncertainty',\n",
    "#                           verbose=False,\n",
    "#                           random_seed=0)\n",
    "scorer = make_scorer(my_custom_loss_func,greater_is_better=True)\n",
    "\n",
    "model=CatBoostRegressor(loss_function='RMSEWithUncertainty',\n",
    "                        verbose=False)\n",
    "#model = GradientBoostingRegressor()\n",
    "\n",
    "random_cv = RandomizedSearchCV(model,\n",
    "                               param_grid,\n",
    "                               cv=2,\n",
    "                               n_iter=10,\n",
    "                               n_jobs=-1,\n",
    "                               scoring = scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d08a6c-13b2-4324-b41f-56278c137e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = random_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46ba02-292b-4c07-9e43-dd88d461efa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(random_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417041d-3a14-4911-b164-377a081f980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4280ec-e09a-4c42-b9f5-e124f58799db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(random_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfaeef-6d70-47b1-b04d-213252d6ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5fb124-3795-45d4-b2d3-b4cb65f3d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-contest",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-symbol",
   "metadata": {
    "code_folding": [
     0,
     19,
     67,
     93,
     181,
     268
    ]
   },
   "outputs": [],
   "source": [
    "def error_line(Mean,Truth,STD):\n",
    "    '''\n",
    "    Simple function to draw an error line plot. \n",
    "    It takes three arrays of the same length, the predicted value (Mean), the truth value (Truth) and the standard deviation (STD).\n",
    "    '''\n",
    "    xline = [0,12000]#\n",
    "    yline = [0,12000]#\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mask = np.random.choice([False, True], len(Mean), p=[0.0, 1]) # To display randomly less points [Remove , Keep] in fraction\n",
    "    plt.errorbar(Mean[mask], Truth[mask], xerr=STD[mask], \n",
    "                 fmt='k.',\n",
    "                 ecolor='k')\n",
    "    plt.plot(xline, yline, '-k')\n",
    "    \n",
    "    plt.xlabel('Predicted value, $\\hat{y}$')\n",
    "    plt.ylabel('True value, $y$ ')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def get_GAP(Pred, Sigma, Truth, n_quantiles):\n",
    "    '''\n",
    "    This function takes the dataframe and calculates the indicator function and the average\n",
    "    we then use this information to estimate the accuracy, goodness and precision of the model.\n",
    "    '''\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "    F = np.zeros(Pred.shape[0])\n",
    "    Indicator_func = np.zeros((Pred.shape[0], perc.shape[0]))\n",
    "\n",
    "    # range of symmetric p-probability intervals\n",
    "    plow = (1 - perc) / 2\n",
    "    pupp = (1 + perc) / 2\n",
    "        \n",
    "    for i in range(len(Pred)):\n",
    "        F[i] = stats.norm.cdf(Truth[i],\n",
    "                              loc=Pred[i],\n",
    "                              scale=Sigma[i])\n",
    "        for proba_low, proba_upp in zip(plow, pupp):\n",
    "            for k in range(len(plow)):\n",
    "                if plow[k] < F[i] <= pupp[k]:\n",
    "                    Indicator_func[i, k] = 1\n",
    "                else:\n",
    "                    Indicator_func[i, k] = 0\n",
    "\n",
    "    avgIndFunc = np.mean(Indicator_func, axis=0)\n",
    "    \n",
    "    a = np.zeros(len(avgIndFunc))\n",
    "    for i in range(len(avgIndFunc)):\n",
    "        if avgIndFunc[i] > perc[i] or avgIndFunc[i] == perc[i]:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "    print(f'Overall uncertainty = {Sigma.mean():.6f}')\n",
    "    U = Sigma.mean()\n",
    "    \n",
    "    ##% Goodness, Precision and Accuracy\n",
    "    \n",
    "\n",
    "    Accuracy = integrate.simps(a, perc)\n",
    "\n",
    "    Prec = a*(avgIndFunc-perc)\n",
    "    Precision = 1-2*integrate.simps(Prec, perc)\n",
    "\n",
    "    Sum = (3*a-2)*(avgIndFunc-perc)\n",
    "    Goodness = 1-integrate.simps(Sum, perc)\n",
    "\n",
    "    return Goodness, Precision, Accuracy, U, Indicator_func,perc\n",
    "    \n",
    "def accuracy_plot(Indicator_func,perc):\n",
    "    '''\n",
    "    This function takes the indicator function and percentiles to draw the accuracy plot.\n",
    "    '''\n",
    "    \n",
    "    L = 100  \n",
    "    mean = np.empty((L, len(perc)))\n",
    "    std = np.empty_like(mean)\n",
    "    avgIndFunc = np.mean(Indicator_func, axis=0)\n",
    "    for p_interv in range(len(perc)):\n",
    "        for l in np.arange(0, L):\n",
    "            samples = random.choices(Indicator_func[:, p_interv],\n",
    "                                     k=Indicator_func.shape[0])\n",
    "            mean[l, p_interv] = np.mean(samples)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "    plt.plot(perc,np.round(avgIndFunc+np.std(mean, axis=0), 3),'--k')\n",
    "    plt.plot(perc,np.round(avgIndFunc-np.std(mean, axis=0), 3),'--k')\n",
    "    plt.plot([0, 1],[0, 1],'-k')\n",
    "    plt.ylabel(r\"$\\overline{\\xi (p)}$\")\n",
    "    plt.xlabel('Probability interval $p$')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "def Error_Acc(Pred,Truth,Sigma,n_quantiles,seed):\n",
    "    np.random.seed(seed)\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "    \n",
    "    mask = np.random.choice([False, True],\n",
    "                            len(Pred),\n",
    "                            p=[0.95, 0.05]) # To display randomly less points [Remove , Keep] in fraction\n",
    "\n",
    "    Truth=Truth[mask]\n",
    "    Pred=Pred[mask]\n",
    "    Sigma=Sigma[mask]\n",
    "    \n",
    "    F = np.zeros(Pred.shape[0])\n",
    "    Indicator_func = np.zeros((Pred.shape[0], perc.shape[0]))\n",
    "\n",
    "    # range of symmetric p-probability intervals\n",
    "    plow = (1 - perc) / 2\n",
    "    pupp = (1 + perc) / 2\n",
    "        \n",
    "    for i in range(len(Pred)):\n",
    "        F[i] = stats.norm.cdf(Truth[i],\n",
    "                              loc=Pred[i],\n",
    "                              scale=Sigma[i])\n",
    "        for proba_low, proba_upp in zip(plow, pupp):\n",
    "            for k in range(len(plow)):\n",
    "                if plow[k] < F[i] <= pupp[k]:\n",
    "                    Indicator_func[i, k] = 1\n",
    "                else:\n",
    "                    Indicator_func[i, k] = 0\n",
    "\n",
    "    avgIndFunc = np.mean(Indicator_func, axis=0)\n",
    "    \n",
    "    a = np.zeros(len(avgIndFunc))\n",
    "    for i in range(len(avgIndFunc)):\n",
    "        if avgIndFunc[i] > perc[i] or avgIndFunc[i] == perc[i]:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "    print('Overall uncertainty = {0:2.2f}'.format(Sigma.mean()))\n",
    "    U = Sigma.mean()\n",
    "    \n",
    "    Accuracy = integrate.simps(a, perc)\n",
    "    print(a)\n",
    "\n",
    "    Prec = a*(avgIndFunc-perc)\n",
    "    print(Prec)\n",
    "    Precision = 1-2*integrate.simps(Prec, perc)\n",
    "\n",
    "    Sum = (3*a-2)*(avgIndFunc-perc)\n",
    "    print(Sum)\n",
    "    Goodness = 1-integrate.simps(Sum, perc)\n",
    "    \n",
    "    print('Accuracy = {0:1.2f}'.format(Accuracy))\n",
    "    print('Precision = {0:1.2f}'.format(Precision))\n",
    "    print('Goodness = {0:1.2f}'.format(Goodness))\n",
    "    \n",
    "    L = 100 \n",
    "    mean = np.empty((L, len(perc)))\n",
    "\n",
    "    for p_interv in range(len(perc)):\n",
    "        for l in np.arange(0, L):\n",
    "            samples = random.choices(Indicator_func[:, p_interv],\n",
    "                                     k=Indicator_func.shape[0])\n",
    "            mean[l, p_interv] = np.mean(samples)\n",
    "\n",
    "    fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\n",
    "    \n",
    "    xline = [0,max(Pred.max(),Truth.max())+max(Pred.max(),Truth.max())*0.1]#\n",
    "    yline = [0,xline[1]]#\n",
    "\n",
    "    ax1.errorbar(Pred, Truth, xerr=Sigma, \n",
    "                 fmt='k.',\n",
    "                 ecolor='k')\n",
    "    ax1.plot(xline, yline, '-k')\n",
    "    ax1.set_xlabel('Predicted value, $\\hat{y}$')\n",
    "    ax1.set_ylabel('True value, $y$ ')\n",
    "    \n",
    "    ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "    ax2.plot(perc,np.round(avgIndFunc+np.std(mean, axis=0), 3),'--k')\n",
    "    ax2.plot(perc,np.round(avgIndFunc-np.std(mean, axis=0), 3),'--k')\n",
    "    ax2.plot([0, 1],[0, 1],'-k')\n",
    "    ax2.set_ylabel(r\"$\\overline{\\xi (p)}$\")\n",
    "    ax2.set_xlabel('Probability interval $p$')\n",
    "    ax2.set_ylim(0,1)\n",
    "    ax2.set_xlim(0,1)\n",
    "    \n",
    "    ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "\n",
    "def Error_Acc_All(Pred,Truth,Sigma,n_quantiles):\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "    \n",
    "    mask = np.random.choice([False, True],\n",
    "                            len(Pred),\n",
    "                            p=[0, 1]) # To display randomly less points [Remove , Keep] in fraction\n",
    "\n",
    "    Truth=Truth[mask]\n",
    "    Pred=Pred[mask]\n",
    "    Sigma=Sigma[mask]\n",
    "    \n",
    "    F = np.zeros(Pred.shape[0])\n",
    "    Indicator_func = np.zeros((Pred.shape[0], perc.shape[0]))\n",
    "\n",
    "    # range of symmetric p-probability intervals\n",
    "    plow = (1 - perc) / 2\n",
    "    pupp = (1 + perc) / 2\n",
    "        \n",
    "    for i in range(len(Pred)):\n",
    "        F[i] = stats.norm.cdf(Truth[i],\n",
    "                              loc=Pred[i],\n",
    "                              scale=Sigma[i])\n",
    "        for proba_low, proba_upp in zip(plow, pupp):\n",
    "            for k in range(len(plow)):\n",
    "                if plow[k] < F[i] <= pupp[k]:\n",
    "                    Indicator_func[i, k] = 1\n",
    "                else:\n",
    "                    Indicator_func[i, k] = 0\n",
    "\n",
    "    avgIndFunc = np.mean(Indicator_func, axis=0)\n",
    "    \n",
    "    a = np.zeros(len(avgIndFunc))\n",
    "    for i in range(len(avgIndFunc)):\n",
    "        if avgIndFunc[i] > perc[i] or avgIndFunc[i] == perc[i]:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "    print('Overall uncertainty = {0:2.2f}'.format(Sigma.mean()))\n",
    "    U = Sigma.mean()\n",
    "    \n",
    "    Accuracy = integrate.simps(a, perc)\n",
    "    print(a)\n",
    "\n",
    "    Prec = a*(avgIndFunc-perc)\n",
    "    print(Prec)\n",
    "    Precision = 1-2*integrate.simps(Prec, perc)\n",
    "\n",
    "    Sum = (3*a-2)*(avgIndFunc-perc)\n",
    "    print(Sum)\n",
    "    Goodness = 1-integrate.simps(Sum, perc)\n",
    "    \n",
    "    print('Accuracy = {0:1.2f}'.format(Accuracy))\n",
    "    print('Precision = {0:1.2f}'.format(Precision))\n",
    "    print('Goodness = {0:1.2f}'.format(Goodness))\n",
    "    \n",
    "    L = 100 \n",
    "    mean = np.empty((L, len(perc)))\n",
    "\n",
    "    for p_interv in range(len(perc)):\n",
    "        for l in np.arange(0, L):\n",
    "            samples = random.choices(Indicator_func[:, p_interv],\n",
    "                                     k=Indicator_func.shape[0])\n",
    "            mean[l, p_interv] = np.mean(samples)\n",
    "\n",
    "    fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\n",
    "    \n",
    "    xline = [0,max(Pred.max(),Truth.max())+max(Pred.max(),Truth.max())*0.1]#\n",
    "    yline = [0,xline[1]]#\n",
    "\n",
    "    ax1.errorbar(Pred, Truth, xerr=Sigma, \n",
    "                 fmt='k.',\n",
    "                 ecolor='k')\n",
    "    ax1.plot(xline, yline, '-k')\n",
    "    ax1.set_xlabel('Predicted value, $\\hat{y}$')\n",
    "    ax1.set_ylabel('True value, $y$ ')\n",
    "    \n",
    "    ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "    ax2.plot(perc,np.round(avgIndFunc+np.std(mean, axis=0), 3),'--k')\n",
    "    ax2.plot(perc,np.round(avgIndFunc-np.std(mean, axis=0), 3),'--k')\n",
    "    ax2.plot([0, 1],[0, 1],'-k')\n",
    "    ax2.set_ylabel(r\"$\\overline{\\xi (p)}$\")\n",
    "    ax2.set_xlabel('Probability interval $p$')\n",
    "    ax2.set_ylim(0,1)\n",
    "    ax2.set_xlim(0,1)\n",
    "    \n",
    "    ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "    \n",
    "def histogram(mc_predictions):\n",
    "    '''\n",
    "    From the Monte Carlo predictions we draw a random point and construct the\n",
    "    histogram of predictions from the model\n",
    "    '''\n",
    "    \n",
    "    Avg = []\n",
    "    rand=np.random.randint(0,mc_predictions.shape[1])\n",
    "    for i in range(mc_predictions.shape[0]):\n",
    "        Avg.append(np.average(mc_predictions[i,rand]))\n",
    "\n",
    "    Std = np.std(Avg)\n",
    "\n",
    "    # Histograms\n",
    "    n_bins = 20\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    N, bins, patches = axs.hist(Avg,\n",
    "                                bins=n_bins,\n",
    "                                label='$\\sigma$ = %2.5f' % Std)\n",
    "    #axs.set_title('Root Mean squared error in barrels for each cell');\n",
    "    fracs = N / N.max()\n",
    "    norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "    for thisfrac, thispatch in zip(fracs, patches):\n",
    "        color = plt.cm.binary(norm(thisfrac))\n",
    "        thispatch.set_facecolor(color)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Number of cases')\n",
    "    plt.xlabel('MSE in predicted value')\n",
    "\n",
    "def APG_calc(Truth, Pred, Sigma,n_quantiles):\n",
    "\n",
    "    mask = np.random.choice([False, True],\n",
    "                            len(Pred),\n",
    "                            p=[0, 1]) # To display randomly less points [Remove , Keep] in fraction\n",
    "\n",
    "    #Truth=Truth[mask]\n",
    "    Pred=Pred[mask]\n",
    "    #Sigma=Sigma[mask]\n",
    "\n",
    "\n",
    "    #n_quantiles = 11\n",
    "\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "\n",
    "    F = np.zeros(Pred.shape[0])\n",
    "    Indicator_func = np.zeros((Pred.shape[0], perc.shape[0]))\n",
    "\n",
    "    # range of symmetric p-probability intervals\n",
    "    plow = (1 - perc) / 2\n",
    "    pupp = (1 + perc) / 2\n",
    "    \n",
    "    for i in range(len(Pred)):\n",
    "        F[i] = stats.norm.cdf(Truth,\n",
    "                          loc=Pred[i],\n",
    "                          scale=Sigma)\n",
    "        for proba_low, proba_upp in zip(plow, pupp):\n",
    "            for k in range(len(plow)):\n",
    "                if plow[k] < F[i] <= pupp[k]:\n",
    "                    Indicator_func[i, k] = 1\n",
    "                else:\n",
    "                    Indicator_func[i, k] = 0\n",
    "\n",
    "    avgIndFunc = np.mean(Indicator_func, axis=0)\n",
    "\n",
    "    a = np.zeros(len(avgIndFunc))\n",
    "    for i in range(len(avgIndFunc)):\n",
    "        if avgIndFunc[i] > perc[i] or avgIndFunc[i] == perc[i]:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "    #print('Overall uncertainty = {0:2.2f}'.format(Sigma.mean()))\n",
    "    U = Sigma.mean()\n",
    "\n",
    "    Accuracy = integrate.simps(a, perc)\n",
    "\n",
    "    Prec = a*(avgIndFunc-perc)\n",
    "    \n",
    "    Precision = 1-2*integrate.simps(Prec, perc)\n",
    "\n",
    "    Sum = (3*a-2)*(avgIndFunc-perc)\n",
    "\n",
    "    Goodness = 1-integrate.simps(Sum, perc)\n",
    "\n",
    "    # print('Accuracy = {0:1.2f}'.format(Accuracy))\n",
    "    # print('Precision = {0:1.2f}'.format(Precision))\n",
    "    # print('Goodness = {0:1.2f}'.format(Goodness))\n",
    "    \n",
    "    return Accuracy, Precision, Goodness, avgIndFunc, U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-rocket",
   "metadata": {},
   "source": [
    "## file import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "x = df.iloc[:,[1,2,3,4,5,6]]              # separate DataFrames for predictor and response features\n",
    "y = df.iloc[:,[7]]\n",
    "\n",
    "mi = mutual_info_regression(x,np.ravel(y)) # calculate mutual information\n",
    "mi /= np.max(mi)                          # calculate relative mutual information\n",
    "\n",
    "indices = np.argsort(mi)[::-1]            # find indicies for descending order\n",
    "\n",
    "print(\"Feature ranking:\")                 # write out the feature importances\n",
    "for f in range(x.shape[1]):\n",
    "    print(\"%d. feature %s = %f\" % (f + 1, x.columns[indices][f], mi[indices[f]]))\n",
    "\n",
    "plt.subplot(111)                          # plot the relative mutual information \n",
    "plt.title(\"Mutual Information\")\n",
    "plt.bar(range(x.shape[1]), mi[indices],\n",
    "       color=\"g\", align=\"center\")\n",
    "plt.xticks(range(x.shape[1]), x.columns[indices],rotation=90)\n",
    "plt.xlim([-1, x.shape[1]])\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=1., top=1., wspace=0.2, hspace=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-cliff",
   "metadata": {},
   "source": [
    "## Model definition and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict mean value and data uncertainty\n",
    "\n",
    "# model = CatBoostRegressor(iterations=100, learning_rate=0.2, loss_function='RMSEWithUncertainty',\n",
    "#                           verbose=False, random_seed=0)\n",
    "#                          #task_type = '0:1')\n",
    "\n",
    "# #train_pool=Pool(X_train,y_train)\n",
    "\n",
    "# model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-marsh",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-environment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "# n_quantiles=11\n",
    "\n",
    "# perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "\n",
    "# Samples = 100\n",
    "\n",
    "# Sigma=np.sqrt(preds[:,1])\n",
    "\n",
    "# Pred = preds[:,0]\n",
    "# Truth = y_test\n",
    "\n",
    "# Pred_array = np.zeros((Sigma.shape[0],Samples))\n",
    "\n",
    "# A_array=np.zeros(Pred.shape[0])\n",
    "# P_array=np.zeros(Pred.shape[0])\n",
    "# G_array=np.zeros(Pred.shape[0])\n",
    "# U_array=np.zeros(Pred.shape[0])\n",
    "\n",
    "# IF_array=np.zeros((Pred.shape[0],n_quantiles))\n",
    "\n",
    "# for i in range(len(Pred)):\n",
    "#     Pred_array[i,:] = np.random.normal(loc=Pred[i],scale=Sigma[i],size=Samples)\n",
    "#     A,P,G,IF,U=APG_calc(Truth[i], Pred_array[i,:], Sigma[i],n_quantiles)\n",
    "#     U_array[i]=U\n",
    "#     A_array[i]=A\n",
    "#     P_array[i]=P\n",
    "#     G_array[i]=G\n",
    "#     IF_array[i,:] = IF\n",
    "\n",
    "# avgIndFunc = np.mean(IF_array, axis=0)\n",
    "\n",
    "# print('Accuracy = {0:1.2f}'.format(np.mean(A_array)))\n",
    "# print('Precision = {0:1.2f}'.format(np.mean(P_array)))\n",
    "# print('Goodness = {0:1.2f}'.format(np.mean(G_array)))\n",
    "\n",
    "# L = 10\n",
    "# mean = np.empty((L, len(perc)))\n",
    "\n",
    "# for p_interv in range(len(perc)):\n",
    "#     for l in np.arange(0, L):\n",
    "#         samples = random.choices(IF_array[:, p_interv],\n",
    "#                                  k=IF_array.shape[0])\n",
    "#         mean[l, p_interv] = np.mean(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "# xline = [0,max(Pred.max(),Truth.max())+max(Pred.max(),Truth.max())*0.1]#\n",
    "# yline = [0,xline[1]]#\n",
    "\n",
    "# ax1.errorbar(Pred, Truth, xerr=Sigma, \n",
    "#              fmt='k.',\n",
    "#              ecolor='k')\n",
    "# ax1.plot(xline, yline, '-k')\n",
    "# ax1.set_xlabel('Predicted value, $\\hat{y}$')\n",
    "# ax1.set_ylabel('True value, $y$ ')\n",
    "\n",
    "# ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "# ax2.plot(perc,np.round(avgIndFunc+np.std(mean, axis=0), 3),'--k')\n",
    "# ax2.plot(perc,np.round(avgIndFunc-np.std(mean, axis=0), 3),'--k')\n",
    "# ax2.plot([0, 1],[0, 1],'-k')\n",
    "# ax2.set_ylabel(r\"$\\overline{\\xi (p)}$\")\n",
    "# ax2.set_xlabel('Probability interval $p$')\n",
    "# ax2.set_ylim(0,1)\n",
    "# ax2.set_xlim(0,1)\n",
    "\n",
    "# ax2.plot(perc, avgIndFunc,'-ok',markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-parish",
   "metadata": {},
   "source": [
    "## Virtual ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "def virt_ensemble(X_train,y_train, num_samples=100, iters=1000, lr=0.2):\n",
    "    ens_preds = []\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=iters, learning_rate=lr, loss_function='RMSEWithUncertainty',\n",
    "                          verbose=False, random_seed=0)\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    \n",
    "    ens_preds = model.virtual_ensembles_predict(X_test, prediction_type='VirtEnsembles', \n",
    "                                                virtual_ensembles_count=num_samples,\n",
    "                                                thread_count=8)\n",
    "    return np.asarray(ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "#Pred_array = np.zeros((Sigma.shape[0],Samples))\n",
    "\n",
    "n_quantiles=11\n",
    "\n",
    "perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "\n",
    "Samples = 10\n",
    "\n",
    "ens_preds=virt_ensemble(X_train,y_train, num_samples=Samples)\n",
    "\n",
    "Pred_array = ens_preds[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Pred_array[:5,1])\n",
    "# print(Truth[:5])\n",
    "# #plt.scatter(np.average(Pred_array,axis=1),Truth)\n",
    "# plt.scatter(Pred_array[:,0],Truth)\n",
    "# plt.scatter(Pred_array[:,1],Truth)\n",
    "# plt.scatter(Pred_array[:,2],Truth)\n",
    "# plt.scatter(Pred_array[:,3],Truth)\n",
    "# plt.scatter(Pred_array[:,9],Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knowledge_u=np.sqrt(np.var(Pred_array,axis=1)) #Knowledge uncertainty\n",
    "Data_u=np.sqrt(np.mean(ens_preds[:,:,1],axis=1)) #Data uncertainty\n",
    "Sigma=Knowledge_u+Data_u\n",
    "\n",
    "Truth = y_test\n",
    "\n",
    "A_array=np.zeros(Pred_array.shape[0])\n",
    "P_array=np.zeros(Pred_array.shape[0])\n",
    "G_array=np.zeros(Pred_array.shape[0])\n",
    "U_array=np.zeros(Pred_array.shape[0])\n",
    "\n",
    "IF_array=np.zeros((Pred_array.shape[0],n_quantiles))\n",
    "\n",
    "for i in range(Pred_array.shape[0]):\n",
    "    #Pred_array[i,:] = np.random.normal(loc=Pred[i],scale=Sigma[i],size=Samples)\n",
    "    A,P,G,IF,U=APG_calc(Truth[i], Pred_array[i,:], Sigma[i],n_quantiles)\n",
    "    U_array[i]=U\n",
    "    A_array[i]=A\n",
    "    P_array[i]=P\n",
    "    G_array[i]=G\n",
    "    IF_array[i,:] = IF\n",
    "\n",
    "avgIndFunc = np.mean(IF_array, axis=0)\n",
    "\n",
    "print('Accuracy = {0:1.2f}'.format(np.mean(A_array)))\n",
    "print('Precision = {0:1.2f}'.format(np.mean(P_array)))\n",
    "print('Goodness = {0:1.2f}'.format(np.mean(G_array)))\n",
    "\n",
    "L = 10\n",
    "mean = np.empty((L, len(perc)))\n",
    "\n",
    "for p_interv in range(len(perc)):\n",
    "    for l in np.arange(0, L):\n",
    "        samples = random.choices(IF_array[:, p_interv],\n",
    "                                 k=IF_array.shape[0])\n",
    "        mean[l, p_interv] = np.mean(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "xline = [0,max(np.mean(Pred_array,axis=1).max(),Truth.max())+max(np.mean(Pred_array,axis=1).max(),Truth.max())*0.1]#\n",
    "yline = [0,xline[1]]#\n",
    "\n",
    "ax1.errorbar(np.mean(Pred_array,axis=1), Truth, xerr=Sigma, \n",
    "             fmt='k.',\n",
    "             ecolor='k')\n",
    "ax1.plot(xline, yline, '-k')\n",
    "ax1.set_xlabel('Predicted value, $\\hat{y}$')\n",
    "ax1.set_ylabel('True value, $y$ ')\n",
    "\n",
    "ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "ax2.plot(perc,np.round(avgIndFunc+np.std(mean, axis=0), 3),'--k')\n",
    "ax2.plot(perc,np.round(avgIndFunc-np.std(mean, axis=0), 3),'--k')\n",
    "ax2.plot([0, 1],[0, 1],'-k')\n",
    "ax2.set_ylabel(r\"$\\overline{\\xi (p)}$\")\n",
    "ax2.set_xlabel('Probability interval $p$')\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_xlim(0,1)\n",
    "\n",
    "ax2.plot(perc, avgIndFunc,'-ok',markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-rochester",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "value='value'\n",
    "xname='Tnumber'\n",
    "yname='Lrate'\n",
    "zname='Tdepth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-gnome",
   "metadata": {
    "code_folding": [
     72
    ]
   },
   "outputs": [],
   "source": [
    "def virt_ensemble(X_train,y_train, num_samples=100, iters=1000, lr=0.2, depth=100):\n",
    "    ens_preds = []\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=iters,\n",
    "                              learning_rate=lr,\n",
    "                              depth=depth,\n",
    "                              loss_function='RMSEWithUncertainty',\n",
    "                              verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    \n",
    "    ens_preds = model.virtual_ensembles_predict(X_test, prediction_type='VirtEnsembles', \n",
    "                                                virtual_ensembles_count=num_samples,\n",
    "                                                thread_count=8)\n",
    "    return np.asarray(ens_preds)\n",
    "\n",
    "def objective(trial):\n",
    "    iterations = trial.suggest_float(\"{0}\".format(xname), 50, 1000)\n",
    "    lrate = trial.suggest_float(\"{0}\".format(yname), 0.001, 0.2)\n",
    "    depth = trial.suggest_float(\"{0}\".format(zname), 4, 16)\n",
    "    \n",
    "    #np.random.seed(0)\n",
    "    \n",
    "\n",
    "    n_quantiles=11\n",
    "\n",
    "    perc = np.linspace(0.0, 1.00, n_quantiles)\n",
    "\n",
    "    Samples = 100\n",
    "\n",
    "    ens_preds=virt_ensemble(X_train,\n",
    "                            y_train,\n",
    "                            num_samples=Samples,\n",
    "                            iters=int(iterations),\n",
    "                            lr=lrate,\n",
    "                            depth = int(depth))\n",
    "\n",
    "    Pred_array = ens_preds[:,:,0]\n",
    "    \n",
    "    Knowledge_u=np.sqrt(np.var(Pred_array,axis=1)) #Knowledge uncertainty\n",
    "    Data_u=np.sqrt(np.mean(ens_preds[:,:,1],axis=1)) #Data uncertainty\n",
    "    Sigma=Knowledge_u+Data_u\n",
    "    \n",
    "    #Pred_array = np.zeros((Sigma.shape[0],Samples))\n",
    "    Truth = y_test\n",
    "    \n",
    "    \n",
    "    A_array=np.zeros(Pred_array.shape[0])\n",
    "    P_array=np.zeros(Pred_array.shape[0])\n",
    "    G_array=np.zeros(Pred_array.shape[0])\n",
    "    U_array=np.zeros(Pred_array.shape[0])\n",
    "\n",
    "    IF_array=np.zeros((Pred_array.shape[0],n_quantiles))\n",
    "\n",
    "    for i in range(Pred_array.shape[0]):\n",
    "        A,P,G,IF,U=APG_calc(Truth[i], Pred_array[i,:], Sigma[i],n_quantiles)\n",
    "        U_array[i]=U\n",
    "        A_array[i]=A\n",
    "        P_array[i]=P\n",
    "        G_array[i]=G\n",
    "        IF_array[i,:] = IF\n",
    "\n",
    "    avgIndFunc = np.mean(IF_array, axis=0)\n",
    "\n",
    "    print('Accuracy = {0:1.2f}'.format(np.mean(A_array)))\n",
    "    print('Precision = {0:1.2f}'.format(np.mean(P_array)))\n",
    "    print('Goodness = {0:1.2f}'.format(np.mean(G_array)))\n",
    "\n",
    "    L = 100\n",
    "    mean = np.empty((L, len(perc)))\n",
    "\n",
    "    for p_interv in range(len(perc)):\n",
    "        for l in np.arange(0, L):\n",
    "            samples = random.choices(IF_array[:, p_interv],\n",
    "                                     k=IF_array.shape[0])\n",
    "            mean[l, p_interv] = np.mean(samples)\n",
    "            \n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "    xline = [0,max(np.mean(Pred_array,axis=1).max(),Truth.max())+max(np.mean(Pred_array,axis=1).max(),Truth.max())*0.1]#\n",
    "    yline = [0,xline[1]]#\n",
    "\n",
    "    ax1.errorbar(np.mean(Pred_array,axis=1), Truth, xerr=Sigma, \n",
    "                 fmt='k.',\n",
    "                 ecolor='k')\n",
    "    ax1.plot(xline, yline, '-k')\n",
    "    ax1.set_xlabel('Predicted value, $\\hat{y}$')\n",
    "    ax1.set_ylabel('True value, $y$ ')\n",
    "\n",
    "    ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "    ax2.plot(perc,np.round(avgIndFunc+np.std(mean, axis=0), 3),'--k')\n",
    "    ax2.plot(perc,np.round(avgIndFunc-np.std(mean, axis=0), 3),'--k')\n",
    "    ax2.plot([0, 1],[0, 1],'-k')\n",
    "    ax2.set_ylabel(r\"$\\overline{\\xi (p)}$\")\n",
    "    ax2.set_xlabel('Probability interval $p$')\n",
    "    ax2.set_ylim(0,1)\n",
    "    ax2.set_xlim(0,1)\n",
    "\n",
    "    ax2.plot(perc, avgIndFunc,'-ok',markersize=5)\n",
    "    plt.show()\n",
    "    \n",
    "    return np.mean(G_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-phenomenon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction= 'maximize')\n",
    "\n",
    "study.optimize(objective,\n",
    "               n_trials=100,\n",
    "               show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "StudyName = 'Maximize_Random_G'\n",
    "\n",
    "joblib.dump(study, StudyName+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study, params = ['Tnumber','Lrate'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study, params = ['Tnumber','Tdepth'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study, params = ['Lrate','Tdepth'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study, params = ['Tnumber','Lrate','Tdepth'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(50,1000,10,dtype=float)\n",
    "y = np.linspace(.001,.2,20,dtype=float)\n",
    "z = np.arange(4,16,1,dtype=float)\n",
    "\n",
    "search_space = {\"{0}\".format(xname): x,\n",
    "                \"{0}\".format(yname): y,\n",
    "                \"{0}\".format(zname): z}\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.GridSampler(search_space),\n",
    "                            direction= 'maximize')\n",
    "\n",
    "study.optimize(objective,\n",
    "               #n_trials=K_space.shape[0] * F_space.shape[0],\n",
    "               n_trials=len(x)*len(y)*len(z),\n",
    "               show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "StudyName = 'example'\n",
    "\n",
    "joblib.dump(study, StudyName+'.pkl')\n",
    "\n",
    "study = joblib.load(StudyName+'.pkl')\n",
    "\n",
    "study.trials_dataframe()\n",
    "\n",
    "df = study.trials_dataframe().drop(['state',\n",
    "                                    'datetime_start',\n",
    "                                    'datetime_complete',\n",
    "                                    'duration',\n",
    "                                    'system_attrs_grid_id',\n",
    "                                    'system_attrs_search_space',\n",
    "                                    'state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "import matplotlib.tri as tri\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "z=df['{0}'.format(value)].values\n",
    "x=df['params_{0}'.format(xname)].values\n",
    "y=df['params_{0}'.format(yname)].values\n",
    "\n",
    "fig, (ax1) = plt.subplots(nrows=1,figsize=(12,6))\n",
    "\n",
    "npoints=77\n",
    "smooth=4\n",
    "\n",
    "# Create grid values first.\n",
    "xi = np.linspace(x.min(), x.max(), npoints)\n",
    "yi = np.linspace(y.min(), y.max(), npoints)\n",
    "\n",
    "# Linearly interpolate the data (x, y) on a grid defined by (xi, yi).\n",
    "triang = tri.Triangulation(x, y)\n",
    "interpolator = tri.LinearTriInterpolator(triang, z)\n",
    "Xi, Yi = np.meshgrid(xi, yi)\n",
    "zi = interpolator(Xi, Yi)\n",
    "\n",
    "zi = gaussian_filter(zi, smooth)\n",
    "\n",
    "levels=10\n",
    "\n",
    "ax1.contour(xi, yi, zi, levels=levels, linewidths=0.1, colors='k')\n",
    "cntr1 = ax1.contourf(xi, yi, zi, levels=levels, cmap=\"inferno\",alpha=0.99)\n",
    "\n",
    "cbar = plt.colorbar(cntr1, ax=ax1)\n",
    "\n",
    "cbar.set_label('ErrorValue', rotation=270,labelpad=30)\n",
    "\n",
    "ax1.set(xlim=(df['params_{0}'.format(xname)].min(),\n",
    "              df['params_{0}'.format(xname)].max()),\n",
    "        ylim=(df['params_{0}'.format(yname)].min(),\n",
    "              df['params_{0}'.format(yname)].max()))\n",
    "ax1.scatter(x,y,s=3,color='darkgray')\n",
    "ax1.set_ylabel('{0}'.format(xname))\n",
    "ax1.set_xlabel('{0}'.format(yname))\n",
    "plt.savefig(\"{0}.png\".format(StudyName), dpi=600,bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-applicant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
